# <center>Subgraph Neural Networks</center>

## 这篇论文做了什么？

这篇论文提出了一种用于学习**子图表示**的子图神经网络SUBGNN，用于对子图进行预测。 SUBGNN可以在大小不同、有多个连通分量（connected components)的较大的子图上进行预测。**所谓的子图预测就是预测特定的子图是否特定的性质。**

所谓的表示学习就是从数据中学习有用的特征，将数据中的有用信息用向量表示，即用向量来表示研究对象。而子图表示学习，就是学习子图中的有用的信息将其表示为向量，用于后续的具体任务。这篇论文中的子图表示关注**近邻（neighborhood）、结构（structure）和位置（position）**三个方面的信息。

这篇论文还设计了一组评估标准，适用于评估子图拓扑的各个方面（邻居，结构，位置）。

## 为什么研究子图？

近年来，图表示学习取得了巨大的进步，但主流方法侧重于学习节点、边或整个图的表示。

在图的node-level和graph-level预测的任务上，深度学习方法已经取得了很好的表现了，但是对子图（subgraph）预测的研究很少。

**graph-level**的表征提供了对图的全局视角但损失了一些精细的局部信息。

**node-level**的表征更关注局部拓扑结构,可能会损失全局信息。

子图结构是许多图相关任务的关键，但是研究人员使用子结构来使GNN架构更高效或提高在节点和边预测任务上的性能，但都没有考虑子图预测。在**Sub2Vec: Feature Learning for Subgraphs**这篇文章提到，学习子图的判别式特征表示可以帮助在图数据上更广泛地利用现有的机器学习算法。

## SubGNN的提出能解决什么问题？

- 运用SUBGNN学习强大的子图表示能力也许能做出超出节点级、边级和图级任务范围的应用程序。因为这样的应用程序要求我们能够推理子图，并通过利用子图驻留在一个巨大的底层图中的事实来预测子图的属性，而SubGNN具备这样的能力。
- SubGNN在生物医学数据集上表现异常良好，在未来疾病诊断和药物开发都有积极的影响。
- SubGNN也有许多潜在的积极应用，如预测社交媒体上的不良行为（如社交媒体上有害社区检测）。同时SubGNN的子图分类能力能够高分辨率剖析用户，如何应用合适也是一个积极的应用。



## 这篇论文如何做的？

本论文中主要通过对8个数据集进行子图分类实验（四个人工数据集，四个真实数据集），表明SUBGNN 实现了在节点级和图形级GNN上对于子图分类有相当大的性能提升，尤其是在生物医学数据集上表现异常出色。

### 实验步骤

首先对于每个数据集，用**GIN**或者**GraphSAINT**进行链路预测训练，获得基图的节点和元节点（meta node）的特征向量(embeddings).（为什么这么做还没明白）。然后用**Sub2Vec算法**（一种学习任意子图特征表示的无监督算法）进行子图嵌入训练。

为了比较公平，所有方法的**前馈部分**都实现为一个带有ReLu非线性激活和dropout的3层前馈网络。

分别用两种前馈网络进行对照实验：

采用可训练节点和子图嵌入的前馈网络

不采用可训练节点和子图嵌入的前馈网络

**注：**

用**GIN**或者**GraphSAINT**进行链路预测训练，就是学习节点的表示，然后转化为子图表示，所谓的元节点其实就是将子图虚拟成一个元节点，这个节点具有整个子图的特征。

Dropout可以比较有效的缓解过拟合的发生，在一定程度上达到正则化的效果。工作原理是：前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强。

**GIN(Graph isomorphism Network):**图同构网络，用于分析GNN的表示能力，通过GIN学习的节点embeddings可以用于类似于节点分类、连接预测这样的任务。出于**HOW POWERFUL ARE GRAPH NEURAL NETWORKS?**这篇文献。

**GraphSAINT：**一种基于图抽样的归纳学习方法，提高训练速率和准确性。出于**GraphSAINT: GRAPH SAMPLING BASED INDUCTIVE**
**LEARNING METHOD**这篇文献



### baseline选择

本论文中用了七种基线方法，应用于子图嵌入训练。

( 1 ) AVG计算每个子图中节点的预训练节点嵌入的平均值。

( 2 ) **MN-GIN（Meta Node GIN）**在预训练节点嵌入的同时，为每个子图训练<u>元节点(又称虚拟节点)</u>

( 3 ) **MN-GAT（Meta Node GAT）**在预训练节点嵌入的同时，为每个子图训练<u>元节点(又称虚拟节点)</u>

( 4 ) **S2V-N (Sub2Vec Neighborhood)**，使用Sub2Vec 计算子图嵌入，保持邻域的属性

( 5 ) **S2V-S (Sub2Vec Structure)**,使用Sub2Vec 计算子图嵌入，保持结构的属性。

( 6 ) **S2V-NS** 将来自S2V-N和S2V-S的子图嵌入连接起来,同时保持邻域和结构两种子图的属性。

( 7 ) **GC （Graph-level GNN）**是一个图分类GNN ( GIN )，它从可训练节点嵌入中聚合节点特征产生子图嵌入；对于GC，每个子图被看作一个独立的图。

**注：**

**基线baseline：**指的是对照组，基准线，就是你这个实验有提升，那么你的提升是对比于什么的提升，被对比的就是baseline。

**为什么进行预训练：**使用尽可能多的训练数据，从中提取出尽可能多的共性特征，从而能让模型对特定任务的学习负担变轻。

**GAT(Graph Attention Networks)：**图注意力网络，通过注意力机制对邻居节点做聚合操作，实现对不同邻居权重的自适应分配，从而大大提到图神经网络模型的表达能力。

### 数据集及实验说明

#### 人工数据集

其中4个数据集为具有特定图属性的子图的数据集，子图将对应度量的分类值作为它们的标签。分别为以下四种标签：

密度（DENSITY）衡量捕获子图内部结构的能力;

切割比率(CUT RATIO)、边界结构。

核数（CORENESS）由子图的平均核数定义，用于测试边界结构和位置;

COMPONENT，子图component的数量，测试内部和外部位置。

**注：**component应该是一个小的连通图，如下图绿色的部分就是两个component

![](%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86.assets/image-20211115001539007.png)

将7种基线和SubGNN方法用于这四个人工数据集，根据这四种度量值分别用Micro-F1和ROC scores衡量分析了这8中方法在子图嵌入上的效果。

为了调查实验中通道编码其预期属性的能力，对通道进行了消融分析。 结果表明，单个通道的性能与其归纳偏差密切相关；

结构通道在 CUT RATIO（边界结构任务）和 DENSITY（内部结构任务）上表现最好，位置通道在 COMPONENT（内部位置任务）上表现最好。 CORENESS 任务主要测量内部结构，但也包含边界位置的概念；发现结构通道和组合通道在这个任务上表现最好。



#### 真实数据集

在四个真实数据集上，同样用这8种方法用Micro-F1和ROC scores进行评估子图分类的效果。下面是这四个实验的详细情况。

**PPI-BP数据集**。PPI-BP是一个真实的分子生物学数据集。给定一组已知与一些共同的生物学过程相关的基因，我们预测它们的共同的细胞功能。**PPI - BP数据集的基础图是人类蛋白质-蛋白质相互作用( PPI )网络**，**子图是网络中参与同一生物学过程的蛋白质的集合**( 如 '醇类生物合成过程 '、 ' m RNA剪切 '等 )。蛋白质子图根据其细胞功能从六个类别进行标记( 例如 "新陈代谢 "、 "发育"等 )。

**注：**基图中节点表示人类蛋白质，如果蛋白质之间存在物理相互作用，则节点之间存在边

​		子图是参与同一生物过程( 如‘酒精生物合成过程 ,‘ m RNA裂解 ,’等。 )的PPI网络中蛋白质的集合

**Hpo- Neuro数据集**：是针对神经病学的真实临床诊断任务，**基图是包含罕见疾病的表型和基因型信息的知识图谱**，节点是表型(症状)，**每个子图由一组与罕见的单基因疾病相关的表型组成**。子图包含与疾病无关的噪声表型，与不正确但相似的疾病相关的干扰表型，以及由HPO层次上升产生的不太具体的表型(例如，从“蛛蛛指”到“手指异常”)。 这些都模拟了不完全诊断过程，使诊断任务更加真实。 子图标签是诊断类别，这是一个包含10个神经系统疾病类别的多标签数据集。

**Hpo- Metab：**是针对罕见代谢紊乱真实临床诊断任务，旨在模拟罕见疾病诊断任务。给定从罕见疾病数据库中智能取样的表型集合，任务是预测与这些表型最一致的代谢或神经疾病的亚类别。**基础图是包含罕见疾病表型和基因型信息的知识图谱**，**子图由与罕见单基因疾病相关的表型集合组成。HPO- METAB子图按代谢紊乱类型进行标记。

**EM-USER数据集。**这是一个用户分析任务。给定一个用户的锻炼历史由该用户的子图表示，我们希望预测该用户的特征。**基础图是一个来自Endomondo的社交健身网络**，是一个共现网络（co-occurrence network），其中节点代表锻炼，边存在于多个用户完成的训练之间，该图包含非常流行的锻炼组合的派系（即小型全连接网络），实验通过识别共现派系，并使用随机网络采样来分解基图中的派系 。**每个子图都表示为一个Endomondo子网络，它组成了用户的锻炼历史**，标签是关于用户的特征(这里是性别)。



## SubGNN相关的描述

SUBGNN 提出了一种新的子图路由机制，在子图的组成部分和底层图的随机抽样锚图块在这之间传播神经信息，从而产生高度准确的子图表示。SUBGNN 指定了三个通道，每个通道用于捕获子图拓扑的不同方面信息。

子图表征学习要求模型对子图特有的一些属性编码。本文中提到的子图属性为下图所示的六种拓扑属性。两列表示子图内部和外部的，三行表示位置、近邻和结构三类。

![image-20211115082927224](%E8%AE%BA%E6%96%87%E6%A2%B3%E7%90%86.assets/image-20211115082927224.png)

**Position.**

border position表示子图与补图之间的距离，它可以区分同构邻域的节点

internal position表示子图中分量（component）之间的距离

**Neighborhood.**

​     border neighborhood表示S中任意节点k步内的节点集合

​     internal neighborhood表示每个子图自己的border neighborhood

子图中的每个连通分量都有自己的边界邻域。

**Structure.**

​     border structure表示子图与border neighborhood之间的连接

internal structure表示子图分量（component）之间的连通性



